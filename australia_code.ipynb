{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eedc0b0-6314-4f4d-b9f9-7908b786a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for 2019-07-01\n",
      "Scraped data for 2019-07-01\n",
      "Fetching data for 2019-07-08\n",
      "Scraped data for 2019-07-08\n",
      "Fetching data for 2019-07-15\n",
      "Scraped data for 2019-07-15\n",
      "Fetching data for 2019-07-22\n",
      "Scraped data for 2019-07-22\n",
      "Fetching data for 2019-07-29\n",
      "Scraped data for 2019-07-29\n",
      "Fetching data for 2019-08-05\n",
      "Scraped data for 2019-08-05\n",
      "Fetching data for 2019-08-12\n",
      "Scraped data for 2019-08-12\n",
      "Fetching data for 2019-08-19\n",
      "Scraped data for 2019-08-19\n",
      "Fetching data for 2019-08-26\n",
      "Scraped data for 2019-08-26\n",
      "Fetching data for 2019-09-02\n",
      "Scraped data for 2019-09-02\n",
      "Fetching data for 2019-09-09\n",
      "Scraped data for 2019-09-09\n",
      "Fetching data for 2019-09-16\n",
      "Scraped data for 2019-09-16\n",
      "Fetching data for 2019-09-23\n",
      "Scraped data for 2019-09-23\n",
      "Fetching data for 2019-09-30\n",
      "Scraped data for 2019-09-30\n",
      "Fetching data for 2019-10-07\n",
      "Scraped data for 2019-10-07\n",
      "Fetching data for 2019-10-14\n",
      "Scraped data for 2019-10-14\n",
      "Fetching data for 2019-10-21\n",
      "Scraped data for 2019-10-21\n",
      "Fetching data for 2019-10-28\n",
      "Scraped data for 2019-10-28\n",
      "Fetching data for 2019-11-04\n",
      "Scraped data for 2019-11-04\n",
      "Fetching data for 2019-11-11\n",
      "Scraped data for 2019-11-11\n",
      "Fetching data for 2019-11-18\n",
      "Scraped data for 2019-11-18\n",
      "Fetching data for 2019-11-25\n",
      "Scraped data for 2019-11-25\n",
      "Fetching data for 2019-12-02\n",
      "Scraped data for 2019-12-02\n",
      "Fetching data for 2019-12-09\n",
      "Scraped data for 2019-12-09\n",
      "Fetching data for 2019-12-16\n",
      "Scraped data for 2019-12-16\n",
      "Fetching data for 2019-12-23\n",
      "Scraped data for 2019-12-23\n",
      "Fetching data for 2019-12-30\n",
      "Scraped data for 2019-12-30\n",
      "Fetching data for 2020-01-06\n",
      "Scraped data for 2020-01-06\n",
      "Fetching data for 2020-01-13\n",
      "Scraped data for 2020-01-13\n",
      "Fetching data for 2020-01-20\n",
      "Scraped data for 2020-01-20\n",
      "Fetching data for 2020-01-27\n",
      "Scraped data for 2020-01-27\n",
      "Fetching data for 2020-02-03\n",
      "Scraped data for 2020-02-03\n",
      "Fetching data for 2020-02-10\n",
      "Scraped data for 2020-02-10\n",
      "Fetching data for 2020-02-17\n",
      "Scraped data for 2020-02-17\n",
      "Fetching data for 2020-02-24\n",
      "Scraped data for 2020-02-24\n",
      "Fetching data for 2020-03-02\n",
      "Scraped data for 2020-03-02\n",
      "Fetching data for 2020-03-09\n",
      "Scraped data for 2020-03-09\n",
      "Fetching data for 2020-03-16\n",
      "Scraped data for 2020-03-16\n",
      "Fetching data for 2020-03-23\n",
      "Scraped data for 2020-03-23\n",
      "Fetching data for 2020-03-30\n",
      "Scraped data for 2020-03-30\n",
      "Fetching data for 2020-04-06\n",
      "Scraped data for 2020-04-06\n",
      "Fetching data for 2020-04-13\n",
      "Scraped data for 2020-04-13\n",
      "Fetching data for 2020-04-20\n",
      "Scraped data for 2020-04-20\n",
      "Fetching data for 2020-04-27\n",
      "Scraped data for 2020-04-27\n",
      "Fetching data for 2020-05-04\n",
      "Scraped data for 2020-05-04\n",
      "Fetching data for 2020-05-11\n",
      "Scraped data for 2020-05-11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chart_date \u001b[38;5;129;01min\u001b[39;00m dates:\n\u001b[0;32m     25\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mchart_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 26\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# Debugging: Print status and partial HTML\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchart_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    586\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    590\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    591\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    592\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    593\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    594\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    595\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    596\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    599\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    600\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 466\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1095\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1095\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:652\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001b[39;00m\n\u001b[0;32m    650\u001b[0m server_hostname_rm_dot \u001b[38;5;241m=\u001b[39m server_hostname\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 652\u001b[0m sock_and_verified \u001b[38;5;241m=\u001b[39m _ssl_wrap_socket_and_match_hostname(\n\u001b[0;32m    653\u001b[0m     sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[0;32m    654\u001b[0m     cert_reqs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcert_reqs,\n\u001b[0;32m    655\u001b[0m     ssl_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_version,\n\u001b[0;32m    656\u001b[0m     ssl_minimum_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_minimum_version,\n\u001b[0;32m    657\u001b[0m     ssl_maximum_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_maximum_version,\n\u001b[0;32m    658\u001b[0m     ca_certs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_certs,\n\u001b[0;32m    659\u001b[0m     ca_cert_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_dir,\n\u001b[0;32m    660\u001b[0m     ca_cert_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_data,\n\u001b[0;32m    661\u001b[0m     cert_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcert_file,\n\u001b[0;32m    662\u001b[0m     key_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_file,\n\u001b[0;32m    663\u001b[0m     key_password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_password,\n\u001b[0;32m    664\u001b[0m     server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname_rm_dot,\n\u001b[0;32m    665\u001b[0m     ssl_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context,\n\u001b[0;32m    666\u001b[0m     tls_in_tls\u001b[38;5;241m=\u001b[39mtls_in_tls,\n\u001b[0;32m    667\u001b[0m     assert_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massert_hostname,\n\u001b[0;32m    668\u001b[0m     assert_fingerprint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massert_fingerprint,\n\u001b[0;32m    669\u001b[0m )\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock_and_verified\u001b[38;5;241m.\u001b[39msocket\n\u001b[0;32m    672\u001b[0m \u001b[38;5;66;03m# Forwarding proxies can never have a verified target since\u001b[39;00m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;66;03m# the proxy is the one doing the verification. Should instead\u001b[39;00m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;66;03m# use a CONNECT tunnel in order to verify the target.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;66;03m# See: https://github.com/urllib3/urllib3/issues/3267.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:805\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_and_match_hostname\u001b[1;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[0;32m    803\u001b[0m         server_hostname \u001b[38;5;241m=\u001b[39m normalized\n\u001b[1;32m--> 805\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m ssl_wrap_socket(\n\u001b[0;32m    806\u001b[0m     sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[0;32m    807\u001b[0m     keyfile\u001b[38;5;241m=\u001b[39mkey_file,\n\u001b[0;32m    808\u001b[0m     certfile\u001b[38;5;241m=\u001b[39mcert_file,\n\u001b[0;32m    809\u001b[0m     key_password\u001b[38;5;241m=\u001b[39mkey_password,\n\u001b[0;32m    810\u001b[0m     ca_certs\u001b[38;5;241m=\u001b[39mca_certs,\n\u001b[0;32m    811\u001b[0m     ca_cert_dir\u001b[38;5;241m=\u001b[39mca_cert_dir,\n\u001b[0;32m    812\u001b[0m     ca_cert_data\u001b[38;5;241m=\u001b[39mca_cert_data,\n\u001b[0;32m    813\u001b[0m     server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[0;32m    814\u001b[0m     ssl_context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m    815\u001b[0m     tls_in_tls\u001b[38;5;241m=\u001b[39mtls_in_tls,\n\u001b[0;32m    816\u001b[0m )\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\ssl_.py:465\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[1;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:  \u001b[38;5;66;03m# Defensive: in CI, we always have set_alpn_protocols\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 465\u001b[0m ssl_sock \u001b[38;5;241m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\ssl_.py:509\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[1;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[0;32m    506\u001b[0m     SSLTransport\u001b[38;5;241m.\u001b[39m_validate_ssl_context_for_tls_in_tls(ssl_context)\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m--> 509\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(sock, server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:455\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[1;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    450\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    451\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msslsocket_class\u001b[38;5;241m.\u001b[39m_create(\n\u001b[0;32m    456\u001b[0m         sock\u001b[38;5;241m=\u001b[39msock,\n\u001b[0;32m    457\u001b[0m         server_side\u001b[38;5;241m=\u001b[39mserver_side,\n\u001b[0;32m    458\u001b[0m         do_handshake_on_connect\u001b[38;5;241m=\u001b[39mdo_handshake_on_connect,\n\u001b[0;32m    459\u001b[0m         suppress_ragged_eofs\u001b[38;5;241m=\u001b[39msuppress_ragged_eofs,\n\u001b[0;32m    460\u001b[0m         server_hostname\u001b[38;5;241m=\u001b[39mserver_hostname,\n\u001b[0;32m    461\u001b[0m         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    462\u001b[0m         session\u001b[38;5;241m=\u001b[39msession\n\u001b[0;32m    463\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1042\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[1;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[0;32m   1039\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   1040\u001b[0m                 \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1042\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1320\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[1;34m(self, block)\u001b[0m\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[0;32m   1319\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mdo_handshake()\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "import csv\n",
    "\n",
    "# Base URL for ARIA Singles Chart\n",
    "base_url = \"https://www.aria.com.au/charts/singles-chart/\"\n",
    "\n",
    "# Generate weekly dates from 2019-07-01 to the most recent Monday\n",
    "start_date = datetime(2019, 7, 1)\n",
    "end_date = datetime(2022, 12, 31)  # Adjust as needed\n",
    "dates = []\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    dates.append(current_date.strftime('%Y-%m-%d'))\n",
    "    current_date += timedelta(weeks=1)\n",
    "\n",
    "# Open a CSV file to store the results\n",
    "with open('aria_singles_chart_2019_to_2022.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Date', 'Rank', 'Song', 'Artist'])\n",
    "\n",
    "    # Loop through each date and scrape data\n",
    "    for chart_date in dates:\n",
    "        url = f\"{base_url}{chart_date}/\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Debugging: Print status and partial HTML\n",
    "        print(f\"Fetching data for {chart_date}\")\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch data for {chart_date} (Status Code: {response.status_code})\")\n",
    "            continue  # Skip to the next date\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all song titles and artists\n",
    "        song_titles = soup.find_all('a', class_='c-chart-item__title')\n",
    "        artist_names = soup.find_all('a', class_='c-chart-item__artist')\n",
    "\n",
    "        # Check if the lengths of titles and artists match\n",
    "        if len(song_titles) != len(artist_names):\n",
    "            print(f\"Mismatch in number of songs and artists for {chart_date}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Write each song and artist to the CSV file\n",
    "        for rank, (song, artist) in enumerate(zip(song_titles, artist_names), start=1):\n",
    "            song_name = song.get_text(strip=True)\n",
    "            artist_name = artist.get_text(strip=True)\n",
    "            writer.writerow([chart_date, rank, song_name, artist_name])\n",
    "\n",
    "        print(f\"Scraped data for {chart_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf27ab-b236-4599-a5a5-877435366d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = 'aria_singles_chart_2019_to_2022.csv'  # Replace with your current file name\n",
    "output_file = 'aria_singles_chart_2019_to_2022_semicolon.csv'  # New file with ; delimiter\n",
    "\n",
    "# Open the existing file and create a new file with ; delimiter\n",
    "with open(input_file, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "     open(output_file, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "    \n",
    "    # Read the input file\n",
    "    reader = csv.reader(infile)\n",
    "    \n",
    "    # Write to the output file with ; as the delimiter\n",
    "    writer = csv.writer(outfile, delimiter=';')\n",
    "    \n",
    "    for row in reader:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"File has been converted and saved as '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed3837-ef6c-4dde-920a-11d47b54decd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "\n",
    "def construct_genius_url(song, artist):\n",
    "    \"\"\"Construct the Genius URL for a given song and artist with proper formatting.\"\"\"\n",
    "    artist_url = artist.strip().lower()\n",
    "    artist_url = re.sub(r'[&]', 'and', artist_url)  # Replace '&' with 'and'\n",
    "    artist_url = re.sub(r'[.,!]', '', artist_url)  # Remove periods, commas, and exclamation marks\n",
    "    artist_url = re.sub(r'\\s+', '-', artist_url)  # Replace spaces with hyphens\n",
    "\n",
    "    title_url = song.strip().lower()\n",
    "    title_url = re.sub(r'\\([^)]*\\)', '', title_url)  # Remove text within parentheses\n",
    "    title_url = re.sub(r'\\s+', ' ', title_url).strip()  # Replace multiple spaces with a single space\n",
    "    title_url = re.sub(r'[!?.,]', '', title_url)  # Remove punctuation marks\n",
    "    title_url = re.sub(r'\\s+', '-', title_url)  # Replace spaces with hyphens\n",
    "    title_url = title_url.replace(\"'\", '')  # Remove apostrophes\n",
    "\n",
    "    return f\"https://genius.com/{artist_url}-{title_url}-lyrics\"\n",
    "\n",
    "def get_lyrics(genius_url):\n",
    "    \"\"\"Fetch lyrics from a Genius song URL.\"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(genius_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        lyrics_container = soup.find('div', {'data-lyrics-container': 'true'})\n",
    "        if not lyrics_container:\n",
    "            print(\"Lyrics container not found.\")\n",
    "            return None\n",
    "\n",
    "        lyrics = []\n",
    "        for element in lyrics_container.find_all(['a', 'span']):\n",
    "            if element.text.strip():\n",
    "                lyrics.append(element.text.strip())\n",
    "\n",
    "        return '\\n'.join(lyrics)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching lyrics: {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_songs_with_lyrics(billboard_file, output_file, start_row=0, end_row=None, existing_songs=None):\n",
    "    \"\"\"Scrape lyrics for songs from the given dataset.\"\"\"\n",
    "    billboard_df = pd.read_csv(billboard_file)\n",
    "\n",
    "    if end_row is None:\n",
    "        end_row = len(billboard_df)\n",
    "\n",
    "    top_songs_df = billboard_df[(billboard_df['Rank'] >= 1) & (billboard_df['Rank'] <= 20)].iloc[start_row:end_row]\n",
    "\n",
    "    lyrics_data = []\n",
    "\n",
    "    if existing_songs is None:\n",
    "        existing_songs = set()\n",
    "\n",
    "    for index, row in top_songs_df.iterrows():\n",
    "        song = row['Song']\n",
    "        artist = row['Artist']\n",
    "\n",
    "        if song in existing_songs:\n",
    "            print(f\"Skipping already processed song: {song} by {artist}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Fetching lyrics for: {song} by {artist}\")\n",
    "\n",
    "        genius_url = construct_genius_url(song, artist)\n",
    "        print(f\"Generated URL: {genius_url}\")\n",
    "\n",
    "        lyrics = get_lyrics(genius_url)\n",
    "        if lyrics:\n",
    "            print(f\"Lyrics fetched successfully. Preview: {lyrics[:100]}...\")\n",
    "        else:\n",
    "            print(\"Lyrics not found.\")\n",
    "\n",
    "        lyrics_data.append({\n",
    "            'Date': row['Date'],\n",
    "            'Rank': row['Rank'],\n",
    "            'Song': song,\n",
    "            'Artist': artist,\n",
    "            'Lyrics': lyrics\n",
    "        })\n",
    "\n",
    "        existing_songs.add(song)\n",
    "\n",
    "        if len(lyrics_data) % 5 == 0:\n",
    "            lyrics_df = pd.DataFrame(lyrics_data)\n",
    "            lyrics_df.to_csv(output_file, index=False)\n",
    "            print(f\"Saved progress to {output_file}\")\n",
    "\n",
    "        time.sleep(3)  # Delay to prevent blocking\n",
    "\n",
    "    if lyrics_data:\n",
    "        lyrics_df = pd.DataFrame(lyrics_data)\n",
    "        lyrics_df.to_csv(output_file, index=False)\n",
    "        print(f\"Final lyrics saved to {output_file}\")\n",
    "\n",
    "# File paths for Canada dataset\n",
    "billboard_file = \"billboard_hot_100_2019_to_2022.csv\"\n",
    "output_file = \"uss_with_lyrics.csv\"\n",
    "\n",
    "# Check if the output file exists and load previously processed songs\n",
    "if os.path.exists(output_file):\n",
    "    existing_data = pd.read_csv(output_file)\n",
    "    existing_songs = set(existing_data['Song'].tolist())\n",
    "else:\n",
    "    existing_songs = None\n",
    "\n",
    "# Execute scraping for the Canada dataset\n",
    "scrape_songs_with_lyrics(billboard_file, output_file, existing_songs=existing_songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac7fe8-c114-429e-ab3a-b4e0bd8c0453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file (assuming it's comma-separated or another delimiter)\n",
    "input_path = \"uss_with_lyrics.csv\"  # Replace with your file path\n",
    "df = pd.read_csv(input_path)  # Read the file with its existing delimiter\n",
    "\n",
    "# Save the file with a semicolon delimiter\n",
    "output_path = \"delimiter_uss.csv\"  # Replace with desired output file name\n",
    "df.to_csv(output_path, index=False, sep=';')\n",
    "\n",
    "print(\"File saved with semicolon as the delimiter.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
